{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import nltk\n",
    "#from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import operator\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import spacy\n",
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#from networkx.algorithms import community\n",
    "#import linkcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify dir\n",
    "Dir = 'D:/Depression_project/data/twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210085\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(Dir+\"/\"+\"tweetsEng_2.json\", mode='r') as file:\n",
    "    reader = json.load(file)   # json.load reads whole json file, json.loads reads string only\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Sun Apr 01 03:08:32 +0000 2018',\n",
       " 'entities': {'hashtags': [{'indices': [122, 130], 'text': 'weather'}],\n",
       "  'symbols': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': []},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'filter_level': 'low',\n",
       " 'geo': None,\n",
       " 'id': 980280726804467713,\n",
       " 'id_str': '980280726804467713',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'place': None,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'source': '<a href=\"http://www.weather-display.com\" rel=\"nofollow\">Weather Display Tweet</a>',\n",
       " 'text': 'Partly cloudy night Temp:3.4C Hum:87 Winds:ENE @ 1.9 mph MaxGust:10 mph Rain:  0.0 mm Baro:1010.6 hpa &amp; Rising slowly #weather',\n",
       " 'timestamp_ms': '1522552112662',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Tue Dec 27 20:15:37 +0000 2011',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': 'Live and detailed North Wales Weather forecasts from Colwyn Bay, Wales, United Kingdom.',\n",
       "  'favourites_count': 2,\n",
       "  'follow_request_sent': None,\n",
       "  'followers_count': 986,\n",
       "  'following': None,\n",
       "  'friends_count': 512,\n",
       "  'geo_enabled': False,\n",
       "  'id': 448263624,\n",
       "  'id_str': '448263624',\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 18,\n",
       "  'location': 'Colwyn Bay, North Wales, UK',\n",
       "  'name': 'Weather North Wales',\n",
       "  'notifications': None,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/389904066/640TheBayWeather.jpg',\n",
       "  'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/389904066/640TheBayWeather.jpg',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1718060557/640TheBayWeather_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1718060557/640TheBayWeather_normal.jpg',\n",
       "  'profile_link_color': '0084B4',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'TheBayWeather',\n",
       "  'statuses_count': 25924,\n",
       "  'time_zone': 'London',\n",
       "  'translator_type': 'none',\n",
       "  'url': 'http://www.thebayweather.com',\n",
       "  'utc_offset': 3600,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_field(data, field):\n",
    "    res = []\n",
    "    for row in data:\n",
    "        res.append(row[field])\n",
    "    print (\"The number of \"+field+ \" is \" + str(len(res)))\n",
    "    return res  \n",
    "\n",
    "def extract_user_field(data, field):\n",
    "    res = []\n",
    "    for row in data:\n",
    "        res.append(row['user'][field])\n",
    "    print (\"The number of \"+field+ \" is \" + str(len(res)))\n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of id is 210085\n",
      "The number of text is 210085\n",
      "The number of created_at is 210085\n",
      "The number of id is 210085\n"
     ]
    }
   ],
   "source": [
    "#username = extract_user_field(data, 'screen_name')\n",
    "userid = extract_user_field(data, 'id')\n",
    "text = extract_field(data, 'text')\n",
    "time = extract_field(data, 'created_at')\n",
    "ID = extract_field(data, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    }
   ],
   "source": [
    "# check to see duplicated ids\n",
    "a = collections.Counter(ID)\n",
    "b = 0\n",
    "for k, v in a.items():\n",
    "    if v > 1:\n",
    "        b += 1\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210085\n"
     ]
    }
   ],
   "source": [
    "mydata = []\n",
    "for i in range(0, len(ID)):\n",
    "    case = {}\n",
    "    case[ID[i]] = {'text': text[i], 'time': time[i], 'userid': userid[i]}\n",
    "    mydata.append(case)\n",
    "print (len(mydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{980280726804467713: {'text': 'Partly cloudy night Temp:3.4C Hum:87 Winds:ENE @ 1.9 mph MaxGust:10 mph Rain:  0.0 mm Baro:1010.6 hpa &amp; Rising slowly #weather',\n",
       "  'time': 'Sun Apr 01 03:08:32 +0000 2018',\n",
       "  'userid': 448263624}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partly cloudy night Temp:3.4C Hum:87 Winds:ENE @ 1.9 mph MaxGust:10 mph Rain:  0.0 mm Baro:1010.6 hpa &amp; Rising slowly #weather\n"
     ]
    }
   ],
   "source": [
    "for case in mydata:\n",
    "    for k, v in case.items():\n",
    "        if k == 980280726804467713:\n",
    "            print (v['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contruct a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978287543203647488</td>\n",
       "      <td>i can't believe we got 4 (FOUR) teasers today</td>\n",
       "      <td>Mon Mar 26 15:08:20 +0000 2018</td>\n",
       "      <td>ROYALTWlCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978287543199215616</td>\n",
       "      <td>Someone just rang my doorbell twice and knocke...</td>\n",
       "      <td>Mon Mar 26 15:08:20 +0000 2018</td>\n",
       "      <td>foggyseagoddess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978287543203647490</td>\n",
       "      <td>People love to show effort when itâ€™s too late</td>\n",
       "      <td>Mon Mar 26 15:08:20 +0000 2018</td>\n",
       "      <td>meganpretty_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978287543220187137</td>\n",
       "      <td>RT @Reaper_Ghosty: Check out Pandoran Shenanig...</td>\n",
       "      <td>Mon Mar 26 15:08:20 +0000 2018</td>\n",
       "      <td>princessarah191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978287543195197441</td>\n",
       "      <td>RT @LoganPaul: new vlog\\nmy special training f...</td>\n",
       "      <td>Mon Mar 26 15:08:20 +0000 2018</td>\n",
       "      <td>pengbabe2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  978287543203647488      i can't believe we got 4 (FOUR) teasers today   \n",
       "1  978287543199215616  Someone just rang my doorbell twice and knocke...   \n",
       "2  978287543203647490      People love to show effort when itâ€™s too late   \n",
       "3  978287543220187137  RT @Reaper_Ghosty: Check out Pandoran Shenanig...   \n",
       "4  978287543195197441  RT @LoganPaul: new vlog\\nmy special training f...   \n",
       "\n",
       "                             time             user  \n",
       "0  Mon Mar 26 15:08:20 +0000 2018       ROYALTWlCE  \n",
       "1  Mon Mar 26 15:08:20 +0000 2018  foggyseagoddess  \n",
       "2  Mon Mar 26 15:08:20 +0000 2018     meganpretty_  \n",
       "3  Mon Mar 26 15:08:20 +0000 2018  princessarah191  \n",
       "4  Mon Mar 26 15:08:20 +0000 2018     pengbabe2017  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'id': ID, 'text': text, 'user': username, 'time': time}\n",
    "df1 = pd.DataFrame(data=d)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# remove deleted or removed posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to part of speech a list of document\n",
    "# PoS type: noun, pronoun, verb, adverb, adjective, conjunction, preposition, interjection, -PRON- refers to personal pronoun\n",
    "def pos(data):  # the input is a document\n",
    "    outputdata = []\n",
    "    import spacy \n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    for line in data:\n",
    "        doc = nlp(line)\n",
    "        newline = []\n",
    "        for token in doc:\n",
    "            if len(token) < 18:\n",
    "                if token.pos_ == 'NOUN' or token.pos_ == 'PROPN' or token.pos_ == 'VERB' or token.pos_ == 'ADJ' \\\n",
    "                or token.pos_ == 'ADV':\n",
    "                    w = token.lemma_\n",
    "                    if w == '-PRON-':\n",
    "                        w = str(token).lower()\n",
    "                    stemmer = nltk.stem.PorterStemmer() \n",
    "                    w = stemmer.stem(w)   \n",
    "                    newline.append(w)\n",
    "        outputdata.append(newline)\n",
    "    return outputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "texts = list(df1['text'])\n",
    "print (len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:25\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now().replace(microsecond=0)\n",
    "cleaned_texts = pos(texts[:5000])\n",
    "end = datetime.datetime.now().replace(microsecond=0)\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_texts[:2]\n",
    "len(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "count = -1\n",
    "f = open(Dir+'/'+'tweets_cleaned.txt',\"w\")\n",
    "for row in cleaned_texts:\n",
    "    count += 1\n",
    "    try:\n",
    "        sent = ' '.join(row)\n",
    "        f.write(str(ID[count])+'#^~^#'+sent+'\\n')\n",
    "    except:\n",
    "        continue    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posAndSaveTo(data, outfiledir):  # the input is a document    \n",
    "    f = open(outfiledir,\"w\")\n",
    "    #outputdata = []\n",
    "    count = -1\n",
    "    import spacy \n",
    "    import en_core_web_sm\n",
    "    nlp = en_core_web_sm.load()\n",
    "    for line in data:\n",
    "        doc = nlp(line)\n",
    "        newline = []\n",
    "        for token in doc:\n",
    "            if len(token) < 18:\n",
    "                if token.pos_ == 'NOUN' or token.pos_ == 'PROPN' or token.pos_ == 'VERB' or token.pos_ == 'ADJ' \\\n",
    "                or token.pos_ == 'ADV':\n",
    "                    w = token.lemma_\n",
    "                    if w == '-PRON-':\n",
    "                        w = str(token).lower()\n",
    "                    stemmer = nltk.stem.PorterStemmer() \n",
    "                    w = stemmer.stem(w)   \n",
    "                    newline.append(w)\n",
    "        count += 1\n",
    "        try:\n",
    "            sent = ' '.join(newline)\n",
    "            f.write(str(ID[count])+'#^~^#'+sent+'\\n')\n",
    "        except:\n",
    "            continue\n",
    "    f.close()\n",
    "        #outputdata.append(newline)\n",
    "    #return outputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posAndSaveTo(text, Dir+'/'+'tweetsEng_cleaned_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check predicted depression posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "Labels = []\n",
    "Ids = []\n",
    "for i in range(70):   \n",
    "    with open(Dir+'/'+'predProb_old/'+'predictedProb_'+str(i)+'.txt',\"r\", errors = 'ignore') as f:\n",
    "        dat = f.readlines()\n",
    "        labels = [x.strip().split()[1] for x in dat] \n",
    "        ids = [x.strip().split()[0] for x in dat] \n",
    "    Labels.extend(labels)\n",
    "    Ids.extend(ids)\n",
    "len(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels = []\n",
    "Ids = []   \n",
    "with open(Dir+'/'+'predictedProbResults_1.txt',\"r\", errors = 'ignore') as f:\n",
    "    dat = f.readlines()\n",
    "    labels = [x.strip().split()[1] for x in dat] \n",
    "    ids = [x.strip().split()[0] for x in dat] \n",
    "Labels.extend(labels)\n",
    "Ids.extend(ids)\n",
    "len(Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label1_id = []\n",
    "for i, l in zip(Ids, Labels):\n",
    "    if float(l) >= 0.9:\n",
    "        label1_id.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3199"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3189"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(label1_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3199\n"
     ]
    }
   ],
   "source": [
    "predDeprPosts = []\n",
    "for case in mydata:\n",
    "    for k, v in case.items():\n",
    "        if k in label1_id:\n",
    "            #print (str(k)+' '+v['text'])\n",
    "            predDeprPosts.append(str(k)+' '+v['text'])\n",
    "print (len(predDeprPosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predDeprPosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f =  open(Dir+'/'+'predDeprPosts.txt', 'w', errors = 'ignore')\n",
    "for line in predDeprPosts:\n",
    "    f.write(line+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
